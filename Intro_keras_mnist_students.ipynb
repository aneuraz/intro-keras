{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneuraz/intro-keras/blob/master/Intro_keras_mnist_students.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DZJlL5bY9sJ1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fsCmwyCe9sKA"
      },
      "source": [
        "# Introduction à keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Spu95Qh09sKC"
      },
      "source": [
        "Le but de ce TP est d'introduire l'utilisation de la library Keras pour le deep-learning. Nous utiliserons cette library à travers 2 exemples de réseaux sur le dataset MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7ijW1kcq9sKE"
      },
      "source": [
        "## La tâche\n",
        "\n",
        "Construire un modèle de réseau de neurones artificiel pour classifier les chiffres manuscrits. \n",
        "Nous disposons du dataset MNIST qui contient 60,000 images pour le train et 10,000 images pour le test. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-9vD4XJM9sKG"
      },
      "source": [
        "<img src=\"https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/mnist.png?raw=1\" >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gRKSNKcM9sKH"
      },
      "source": [
        "### Import des modules python requis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "moj5yGog9sKK"
      },
      "outputs": [],
      "source": [
        "import numpy as np                   \n",
        "import matplotlib.pyplot as plt     \n",
        "import random                       \n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uQzsprIO9sKO"
      },
      "source": [
        "\n",
        "## Charger les datasets d'entrainement et de test\n",
        "\n",
        "Le dataset MNIST est un dataset jouet. Il est fourni directement dans keras. On peut donc le charger avec la 2 fonctions: `mnist = tf.keras.datasets.mnist` puis `mnist.load_data()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aQM5Noo29sKQ"
      },
      "outputs": [],
      "source": [
        "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", Y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BU8SzK7_9sKW"
      },
      "source": [
        "Avec matplotlib, on peut afficher quelques images d'exemple en utilisant la fonction ci-dessous:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GUWMD8IA9sKY"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (9,9) # pour que les images s'affichent en plus grand dans le notebook\n",
        "\n",
        "random.seed(3)\n",
        "nums = [random.randint(0, len(X_train)) for x in range(9)]\n",
        "\n",
        "for i, num in enumerate(nums):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(Y_train[num]))\n",
        "    \n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dNEaFqc29sKa"
      },
      "source": [
        "Affichons la matrice correspondant à un seul chiffre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HnCQB5Nx9sKa"
      },
      "outputs": [],
      "source": [
        "# une petite fonction pour afficher les matrices joliment\n",
        "def matprint(mat, fmt=\"g\"):\n",
        "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
        "    for x in mat:\n",
        "        for i, y in enumerate(x):\n",
        "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
        "        print(\"\")\n",
        "\n",
        "# now print!        \n",
        "matprint(X_train[nums[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CvLUvU2o9sKc"
      },
      "source": [
        "Chaque pixel est un 8-bit integer dans le range 0-255. 0 = Noir, 255 = Blanc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5yVhiiDW9sKd"
      },
      "source": [
        "\n",
        "\n",
        "## Reformater l'input\n",
        "\n",
        "Pour simplifier l'architecture du réseau, nous allons reformater les images.\n",
        "\n",
        "Transformer les matrices 28 x 28 en vecteurs de taille 784.\n",
        "\n",
        "Puis normaliser les valeurs vers un range [0-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BAVo-GXz9sKd"
      },
      "source": [
        "<img src='https://github.com/AviatorMoser/keras-mnist-tutorial/blob/master/flatten.png?raw=1' >"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X5gapPMJ9sKe"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(60000, 784) \n",
        "X_test = X_test.reshape(10000, 784)   \n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6SYKFevH--O"
      },
      "source": [
        "# Construisons un premier réseau\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jcQ5MYaSIM_z"
      },
      "source": [
        "## Initialiser le modèle avec `Sequential()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gZ4KizlzITqk"
      },
      "source": [
        "Sequential permet de construire des réseaux linéaires: une entrée - des traitements - une sortie.\n",
        "\n",
        "Pour des architectures plus complexes, il faut aller voir du côté de l'api `Functional` [Keras functional API](https://www.tensorflow.org/guide/keras/functional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9n_-S8XqIJ-C"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k5xD9KGZJA2v"
      },
      "source": [
        "## Ajouter des couches au modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yk4XmnaRJFgC"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    tf.keras.layers.Dense(64, input_shape=(784,))\n",
        "    ) # une couche dense (fully connected) de taille 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T9wdK4UWJ_9I"
      },
      "source": [
        "![Texte alternatif…](https://slugnet.jarrodkahn.com/_images/tikz-be0593f4dad31d763e7f8371668007610e7907c1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G5bAISjFJSV3"
      },
      "source": [
        "Notez que pour la première couche il faut préciser la forme des données. Ici, nous avons des données de dimension 1 (vecteurs) et de taille 784. (Si nous avions des données en dimension 2 nous aurions eu une valeur de shape du type `(28,28)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PcJA6VpnKOof"
      },
      "source": [
        "## Ajouter une activation (Relu)\n",
        "\n",
        "![Texte alternatif…](https://miro.medium.com/max/1192/1*4ZEDRpFuCIpUjNgjDdT2Lg.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9-hBpMWiKNOH"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    tf.keras.layers.Activation('relu')\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ptS9nRQFLIYE"
      },
      "source": [
        "## Ajouter une couche de Dropout\n",
        "\n",
        "Le dropout est une technique de régularisation qui permet d'éviter l'overfitting. Elle consiste à \"oublier\" aléatoirement un certain nombre de poids du réseau\n",
        "\n",
        "![Texte alternatif…](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W1Tg8pUIOaxi"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    tf.keras.layers.Dropout(0.5)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "U16DnHsuLmrW"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yYsZtfTALuMS"
      },
      "source": [
        "## Ajouter le classifieur \n",
        "\n",
        "Pour le moment, nous avons encodé notre input à l'aide de nos premières couches mais il faut à présent projeter cette représentation dans l'espace des labels (cible) afin de faire un prédiction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aswlmtlBL-7A"
      },
      "outputs": [],
      "source": [
        "model.add(\n",
        "    tf.keras.layers.Dense(10))\n",
        "model.add(\n",
        "    tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "acuRbSa_O9aD"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, 'model1.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "92PTa_t5PQYj"
      },
      "source": [
        "## Compiler le modèle pour obtenir un modèle executable\n",
        "Il faut préciser la fonction de coût à utiliser. C'est la fonction qui va être dérivée pour obtenir les gradients d'opitimisation. Elle dépend de la tâche. Ici nous cherchons à faire une classification à plusieurs catégories, il faut donc utiliser une `categorical_crossentropy`. Et comme nos Y sont codés en [1,2,3,...] il faut utiliser la fonction `sparse_categorical_crossentropy`. Pour plus d'info: [loss-and-loss-functions-for-training-deep-learning-neural-networks](https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/)\n",
        "\n",
        "Il faut aussi préciser l'algorithme à utiliser pour optimiser les poids (des variantes de gradient descent), ici `adam`\n",
        "\n",
        "et enfin préciser la métrique d'évaluation, ici `accuracy`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "E06u134TMcgB"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kdE0vCJHQxnb"
      },
      "source": [
        "## Entrainer le modèle \n",
        "\n",
        "Nous pouvons enfin entrainer notre premier modèle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yrYq_8_QMrXs"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train,        # input\n",
        "          Y_train,        # output\n",
        "          batch_size=128, # taille des minibatches\n",
        "          epochs=5,       # nombre d'epochs (passages sur les données )\n",
        "          verbose=1)      # option paramètrant la quantité d'informations à afficher pendant l'entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2F2yLwRARRvr"
      },
      "source": [
        "## Evaluer le modèle sur les données test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kFlj3PUYNKgT"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, Y_test)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UG0VrFrcThXW"
      },
      "source": [
        "## Inspecter les résultats plus précisément avec `classification_report` et `confusion_matrix`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OoWKvxj7SqBt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "predicted = model.predict(X_test)\n",
        "predicted_classes = np.argmax(predicted, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YSNTN6LiS8pz"
      },
      "outputs": [],
      "source": [
        "print(confusion_matrix(Y_test, predicted_classes))\n",
        "print(classification_report(Y_test, predicted_classes)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EcL4XyNzRdhN"
      },
      "source": [
        "# TODO\n",
        "\n",
        "## Plot quelques exemples correctement et incorrectement classifiés\n",
        "\n",
        "## Faites varier les paramètres du réseau pour essayer d'obtenir de meilleurs résultats\n",
        "\n",
        "Ici les paramètres que l'on peut faire varier comprennent: \n",
        "- La taille de la couche dense\n",
        "- Le nombre de couches denses \n",
        "- La fonction d'activation de la/les couches denses\n",
        "- Les valeurs de Dropout \n",
        "- La taille des batchs \n",
        "- La fonction d'optimisation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XM6Vza-S9sK7"
      },
      "source": [
        "# Passons à la convolution\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZHmuehL79sK7"
      },
      "source": [
        "\n",
        "Le but de la convolution est de générer des cartes de features basées sur les pixels originaux mais permettant d'obtenir des informations plus riches (courbes, angles, côtés,...) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ODKgWtX99sK7"
      },
      "source": [
        "![Texte alternatif…](https://miro.medium.com/max/2340/1*Fw-ehcNBR9byHtho-Rxbtw.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cSHEwvGl9sK7"
      },
      "source": [
        "Dans l'exemple ci-dessus, on part d'une matrice 5x5 et on fait passer un kernel de convolution de taille 3x3. Le résultat de la convolution est un dot product entre la matrice et le kernel. On déplace le kernel sur l'image afin la couvrir en totalité. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hMjs4LIefSts"
      },
      "source": [
        "```python\n",
        "tf.keras.layers.Conv2D(32,                      # on crée 32 filtres\n",
        "                       (3, 3),                  # kernel de taille (3,3)\n",
        "                       input_shape=(28,28,1)))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M4p7w6Ac9sK8"
      },
      "source": [
        "Les convolutions sont appliquées avec ensuite une couche de **max-pooling** (cf illustration ci-dessous)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EUsU37K39sK8"
      },
      "source": [
        "![Texte alternatif…](https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3HkcxLf0e9Iq"
      },
      "source": [
        "```python\n",
        "tf.keras.layers.MaxPooling2D(pool_size=(2,2))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HAjNr8hshMU8"
      },
      "source": [
        "En général les modules de convolution se présentent comme cela: \n",
        "\n",
        "```\n",
        "Convolution \n",
        "Activation\n",
        "Convolution\n",
        "Activation\n",
        "Pooling\n",
        "```\n",
        "\n",
        "On peut mettre autant de modules que l'on veut\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "77Vh2FSPfcGw"
      },
      "source": [
        "A la fin d'une série de convolutions/pooling, il faut applanir l'output avant de le faire passer dans une couche dense. Pour cela, la fonction `tf.keras.Flatten` est utile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pCRgd2iq9sK9"
      },
      "source": [
        "## Preprocessing pour le réseau de convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PWZqgcKaXmr6"
      },
      "source": [
        "### Recharger le dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "v9OkDCj99sK-"
      },
      "outputs": [],
      "source": [
        "# Recharger le dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6w4rzqyxXqHw"
      },
      "source": [
        "### Reformater les inputs vers (n_sample,28,28,1) et normaliser\n",
        "n_sample = nombre d'exemples dans le dataset\n",
        "28x28 = taille de la matrice\n",
        "1 = nombre de couches (ici ce sont des images en noir et blanc, donc une seule couche) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tekOawnX9sK_"
      },
      "outputs": [],
      "source": [
        "# Ajouter une dimension supplémentaire pour représenter la couche unique à X_train et X_test\n",
        "\n",
        "\n",
        "# Normaliser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6diAhKL7iYHw"
      },
      "source": [
        "## Créer le modèle "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "TySQMZdbab0e"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()                                 \n",
        "\n",
        "# Ajouter un module de convolution\n",
        "\n",
        "# Ajouter une couche Dense\n",
        "\n",
        "# Ajouter le classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y-MZdnsf9sLB"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zUtfmp1X9sLC"
      },
      "outputs": [],
      "source": [
        "# Optimiseur ne bouge pas\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HZxiHtkkYjtU"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, Y_train,  epochs=5, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WpCEKAaPZX9D"
      },
      "source": [
        "# TODO\n",
        "\n",
        "## Evaluer le modèle et interpréter les résultats\n",
        "\n",
        "## Faites varier les paramètres du réseau pour essayer d'obtenir de meilleurs résultats\n",
        "\n",
        "Ici les paramètres que l'on peut faire varier comprennent: \n",
        "- Convolution:\n",
        "  - Nombre de filtres, \n",
        "  - taille du kernel\n",
        "- Pooling: \n",
        "  - Fonction de pooling\n",
        "  - taille de pooling\n",
        "- Nombre de couches de convolution\n",
        "- la fonction d'activation des couches de convolution\n",
        "- La taille de la couche dense\n",
        "- Le nombre de couches denses \n",
        "- La fonction d'activation de la/les couches denses\n",
        "- Les valeurs de Dropout \n",
        "- La taille des batchs \n",
        "- La fonction d'optimisation \n",
        "\n",
        "## Pour aller plus loin: \n",
        "- Tester la `BatchNormalization` [https://keras.io/layers/normalization/](https://keras.io/layers/normalization/)\n",
        "- Utiliser un générateur `ImageDataGenerator` pour augmenter le train set en faisant varier les paramètres des images (taille, rotation, zoom, ...). Il faudra aussi adapter la fonction de fit du modèle et utiliser `fit_generator`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Intro_keras_mnist_students.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Tensorflow (GPU)",
      "language": "python",
      "name": "py3.6-tfgpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
